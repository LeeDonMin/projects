{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b82288e",
      "metadata": {
        "id": "6b82288e"
      },
      "source": [
        "### RAG 기본 구조 이해하기\n",
        "\n",
        "1. 사전작업(Pre-processing): 데이터 소스를 Vector DB (저장소) 에 문서를 로드-분할-임베딩-저장 \n",
        "\n",
        "- 1단계 문서로드(Document Load): 문서 내용을 불러옴\n",
        "- 2단계 분할(Text Split): 문서를 특정 기준(Chunk) 으로 분할\n",
        "- 3단계 임베딩(Embedding): 분할된(Chunk) 를 임베딩하여 저장\n",
        "- 4단계 벡터DB 저장: 임베딩된 Chunk 를 DB에 저장\n",
        "\n",
        "2. RAG 수행(RunTime) - 5~8 단계\n",
        "\n",
        "- 5단계 검색기(Retriever): 쿼리(Query) 를 바탕으로 DB에서 검색하여 결과를 가져오기 위하여 리트리버를 정의\n",
        "- 6단계 프롬프트: RAG 를 수행하기 위한 프롬프트를 생성. 프롬프트의 context 에는 문서에서 검색된 내용이 입력됨. 프롬프트 엔지니어링을 통하여 답변의 형식을 지정 가능\n",
        "- 7단계 LLM: 모델을 정의 (GPT-3.5, GPT-4, Claude, etc..)\n",
        "- 8단계 Chain: 프롬프트 - LLM - 출력 에 이르는 체인을 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c423a8",
      "metadata": {
        "id": "01c423a8"
      },
      "source": [
        "## 환경설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ac5cb321",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain in ./.local/lib/python3.10/site-packages (0.3.3)\n",
            "Requirement already satisfied: langchain-openai in ./.local/lib/python3.10/site-packages (0.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.local/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.local/lib/python3.10/site-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.local/lib/python3.10/site-packages (from langchain) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in ./.local/lib/python3.10/site-packages (from langchain) (0.3.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.local/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.local/lib/python3.10/site-packages (from langchain) (0.1.133)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./.local/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.local/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./.local/lib/python3.10/site-packages (from langchain-openai) (1.51.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in ./.local/lib/python3.10/site-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.9.0\n",
            "    Uninstalling h11-0.9.0:\n",
            "      Successfully uninstalled h11-0.9.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.9.1\n",
            "    Uninstalling httpcore-0.9.1:\n",
            "      Successfully uninstalled httpcore-0.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.13.3\n",
            "    Uninstalling httpx-0.13.3:\n",
            "      Successfully uninstalled httpx-0.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googletrans 3.1.0a0 requires httpx==0.13.3, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Sg4cuF6Ip9Ep",
      "metadata": {
        "id": "Sg4cuF6Ip9Ep"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langsmith in ./.local/lib/python3.10/site-packages (0.1.133)\n",
            "Requirement already satisfied: python-dotenv in ./.local/lib/python3.10/site-packages (1.0.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.10/site-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in ./.local/lib/python3.10/site-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.local/lib/python3.10/site-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: anyio in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (4.6.0)\n",
            "Requirement already satisfied: certifi in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.6)\n",
            "Requirement already satisfied: idna in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (2.10)\n",
            "Requirement already satisfied: sniffio in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langsmith) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langsmith python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "lOCXQe4xtHPn",
      "metadata": {
        "id": "lOCXQe4xtHPn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# API 키 정보 로드\n",
        "load_dotenv('./.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "34687156",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[API KEY]\n",
            "sk-l0rAOwEsqXqeXoZsj4jppfpH52TOFQezaNohE3ztURT3BlbkFJmqnZl5n_izzgDQoGAxMjXYm0nj4BrEzXWrArHJABUA\n",
            "[LANGCHAIN_PROJECT]\n",
            "RAG_test\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'RAG_test'\n",
        "print(f\"[LANGCHAIN_PROJECT]\\n{os.environ['LANGCHAIN_PROJECT']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a224fd32",
      "metadata": {
        "id": "a224fd32"
      },
      "source": [
        "API KEY 를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "zgNuMaDGp_om",
      "metadata": {
        "collapsed": true,
        "id": "zgNuMaDGp_om"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain-teddynote in ./.local/lib/python3.10/site-packages (0.3.6)\n",
            "Requirement already satisfied: langchain in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.3.3)\n",
            "Requirement already satisfied: langgraph in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.2.35)\n",
            "Requirement already satisfied: kiwipiepy in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.19.0)\n",
            "Requirement already satisfied: konlpy in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.6.0)\n",
            "Requirement already satisfied: rank-bm25 in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.2.2)\n",
            "Requirement already satisfied: pinecone-client[grpc] in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (5.0.1)\n",
            "Requirement already satisfied: pinecone-text in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.9.0)\n",
            "Requirement already satisfied: olefile in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (0.47)\n",
            "Requirement already satisfied: pdf2image in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (1.17.0)\n",
            "Requirement already satisfied: openai in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (1.51.2)\n",
            "Requirement already satisfied: deepl in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (1.19.1)\n",
            "Requirement already satisfied: feedparser in ./.local/lib/python3.10/site-packages (from langchain-teddynote) (6.0.11)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.local/lib/python3.10/site-packages (from deepl->langchain-teddynote) (2.32.3)\n",
            "Requirement already satisfied: sgmllib3k in ./.local/lib/python3.10/site-packages (from feedparser->langchain-teddynote) (1.0.0)\n",
            "Requirement already satisfied: kiwipiepy-model<0.20,>=0.19 in ./.local/lib/python3.10/site-packages (from kiwipiepy->langchain-teddynote) (0.19.0)\n",
            "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from kiwipiepy->langchain-teddynote) (4.66.5)\n",
            "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from kiwipiepy->langchain-teddynote) (1.26.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in ./.local/lib/python3.10/site-packages (from konlpy->langchain-teddynote) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in ./.local/lib/python3.10/site-packages (from konlpy->langchain-teddynote) (5.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (0.3.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (0.1.133)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from langchain->langchain-teddynote) (8.5.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from langgraph->langchain-teddynote) (2.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (0.6.1)\n",
            "Requirement already satisfied: sniffio in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.local/lib/python3.10/site-packages (from openai->langchain-teddynote) (4.12.2)\n",
            "Requirement already satisfied: pillow in ./.local/lib/python3.10/site-packages (from pdf2image->langchain-teddynote) (10.4.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.7)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (2.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.65.0)\n",
            "Requirement already satisfied: grpcio>=1.44.0 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.66.2)\n",
            "Requirement already satisfied: lz4>=3.1.3 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.3.3)\n",
            "Requirement already satisfied: protobuf<5.0,>=4.25 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.25.5)\n",
            "Requirement already satisfied: protoc-gen-openapiv2<0.0.2,>=0.0.1 in ./.local/lib/python3.10/site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.1)\n",
            "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in ./.local/lib/python3.10/site-packages (from pinecone-text->langchain-teddynote) (4.1.0)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.5 in ./.local/lib/python3.10/site-packages (from pinecone-text->langchain-teddynote) (3.9.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in ./.local/lib/python3.10/site-packages (from pinecone-text->langchain-teddynote) (1.0.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in ./.local/lib/python3.10/site-packages (from pinecone-text->langchain-teddynote) (2.32.0.20240914)\n",
            "Requirement already satisfied: wget<4.0,>=3.2 in ./.local/lib/python3.10/site-packages (from pinecone-text->langchain-teddynote) (3.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (1.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in ./.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->langchain-teddynote) (2.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->langchain-teddynote) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->langchain-teddynote) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->langchain-teddynote) (0.14.0)\n",
            "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy->langchain-teddynote) (24.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain->langchain-teddynote) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in ./.local/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph->langchain-teddynote) (1.1.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->langchain-teddynote) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->langchain-teddynote) (1.0.0)\n",
            "Requirement already satisfied: click in ./.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (8.1.7)\n",
            "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain-teddynote) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain-teddynote) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->deepl->langchain-teddynote) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->langchain-teddynote) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain->langchain-teddynote) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain->langchain-teddynote) (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-teddynote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "nGKuTxtsqmp9",
      "metadata": {
        "id": "nGKuTxtsqmp9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith 추적을 시작합니다.\n",
            "[프로젝트명]\n",
            "test11\n"
          ]
        }
      ],
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"test11\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0024d0c5",
      "metadata": {
        "id": "0024d0c5"
      },
      "source": [
        "[LangSmith](https://smith.langchain.com)를 사용하여 체인이나 에이전트 내부에서 정확히 무슨 일이 일어나고 있는지 조사 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de11a49",
      "metadata": {
        "id": "2de11a49"
      },
      "source": [
        "## 네이버 뉴스 기반 QA(Question-Answering) 챗봇\n",
        "\n",
        "네이버 뉴스기사의 내용에 대해 질문할 수 있는 **뉴스기사 QA 앱** 을 구축할 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "puiooOMMlebQ",
      "metadata": {
        "collapsed": true,
        "id": "puiooOMMlebQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain-community in ./.local/lib/python3.10/site-packages (0.3.2)\n",
            "Requirement already satisfied: langchain_openai in ./.local/lib/python3.10/site-packages (0.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.local/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.local/lib/python3.10/site-packages (from langchain-community) (3.10.9)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.3.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.3.10)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.1.133)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./.local/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./.local/lib/python3.10/site-packages (from langchain_openai) (1.51.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in ./.local/lib/python3.10/site-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.local/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.local/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in ./.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "sbOVchN5rNmI",
      "metadata": {
        "collapsed": true,
        "id": "sbOVchN5rNmI"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File path data/SPRI_AI_Brief_2023년12월호_F.pdf is not a valid file or url",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/elicer/03. RAG_Basic.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ycrgspwaccjrkrnq.tunnel-pt.elice.io/home/elicer/03.%20RAG_Basic.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m PyPDFLoader\n\u001b[1;32m      <a href='vscode-notebook-cell://ycrgspwaccjrkrnq.tunnel-pt.elice.io/home/elicer/03.%20RAG_Basic.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# PDF 파일 로드. 파일의 경로 입력\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ycrgspwaccjrkrnq.tunnel-pt.elice.io/home/elicer/03.%20RAG_Basic.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m loader \u001b[39m=\u001b[39m PyPDFLoader(\u001b[39m\"\u001b[39;49m\u001b[39mdata/SPRI_AI_Brief_2023년12월호_F.pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ycrgspwaccjrkrnq.tunnel-pt.elice.io/home/elicer/03.%20RAG_Basic.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 페이지 별 문서 로드\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ycrgspwaccjrkrnq.tunnel-pt.elice.io/home/elicer/03.%20RAG_Basic.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:241\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password, headers, extract_images, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpypdf package not found, please install it with `pip install pypdf`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[0;32m--> 241\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(file_path, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser \u001b[39m=\u001b[39m PyPDFParser(\n\u001b[1;32m    243\u001b[0m     password\u001b[39m=\u001b[39mpassword,\n\u001b[1;32m    244\u001b[0m     extract_images\u001b[39m=\u001b[39mextract_images,\n\u001b[1;32m    245\u001b[0m     extraction_mode\u001b[39m=\u001b[39mextraction_mode,\n\u001b[1;32m    246\u001b[0m     extraction_kwargs\u001b[39m=\u001b[39mextraction_kwargs,\n\u001b[1;32m    247\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:117\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(temp_pdf)\n\u001b[1;32m    116\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path):\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile path \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not a valid file or url\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path)\n",
            "\u001b[0;31mValueError\u001b[0m: File path data/SPRI_AI_Brief_2023년12월호_F.pdf is not a valid file or url"
          ]
        }
      ],
      "source": [
        "### PDF 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 페이지 별 문서 로드\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db57b978",
      "metadata": {},
      "outputs": [],
      "source": [
        "### csv 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "# CSV 파일 로드\n",
        "loader = CSVLoader(file_path=\"data/titanic.csv\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06dcdabf",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 폴더 내의 모든 파일 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.txt\", show_progress=True)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")\n",
        "\n",
        "\n",
        "### 폴더 내의 모든 pdf 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[2500:3000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473655b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Python 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import PythonLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"**/*.py\", loader_cls=PythonLoader)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8435e8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### txt 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"data/appendix-keywords.txt\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f3d1b0fc",
      "metadata": {
        "id": "f3d1b0fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "LPaLNIrHsTF5",
      "metadata": {
        "id": "LPaLNIrHsTF5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pypdf in ./.local/lib/python3.10/site-packages (5.0.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in ./.local/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.local/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9f69f249",
      "metadata": {
        "id": "9f69f249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서의 수: 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://jeong-daniel.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%98-Backbone(%EB%B0%B1%EB%B3%B8)-%EC%A0%95%EB%A6%AC/'}, page_content='  딥러닝 모델의 Backbone(백본) 정리  Posted  Sep 20, 2022    Updated  Jan 8, 2023    By  Jeong Daniel    4 min read최근 과제를 하나 받아서 수행하고 있는데 백본 네트워크에 대해서 정리가 필요했다. 평소 컴퓨터비전 객체추적, 상황인식에 대해서 어느정도 알고 있었다고 생각했지만 또 역시 자세히 들여다보니 많은 부분으로 나누어져있다. 그래도 하나하나 짚어가다보면 끝이 보이겠지객체검출에 있어서는 One-Stage와 Two-Stage로 나누어지는데 객체 검출을 할때 두단계를 사용할 것인가 한단계로 통합할 것인가로 구분된다. 단계의 구분은 내가 원하는 물체가 있을 만한곳을 탐색하는 Location의 문제이고 그 물체가 어떤 것인지 구분하는 Classification으로 구분되는데 지금은 이것을 따지고자 쓴 게시글이 아니니 Backbone이 무엇인지부터 보자위 그림에서 처럼 이미지가 들어오면 Backbone - Neck - Head로 구분을 할 수 있다.Backbone(백본)은 입력 이미지를 feature map으로 변형시켜주는 부분이다. ImageNet 데이터셋으로 pre-trained 시킨 VGG16, ResNet-50 등이 대표적인 Backbone이다. 헤드는 Backbone에서 추출한 feature map의 location 작업을 수행하는 부분이다. 헤드에서 predict classes와 bounding boxes 작업이 수행된다.Neck(넥)은 Backbone과 Head를 연결하는 부분으로, feature map을 refinement(정제), reconfiguration(재구성)한다. 대표적으로 FPN(Feature Pyramid Network), PAN(Path Aggregation Network), BiFPN, NAS-FPN 등이 있다.Head(헤드)는 크게 Dense Prediction, Sparse Prediction으로 나뉘는데, 이는 Object Detection의 종류인 1-stage인지 2-stage에서 구분된다.YOLO v4의 아키텍쳐는 다음과 같다. 1) Backbone : CSP-Darkent53 2) Neck : SPP(Spatial Pyramid Pooling), PAN(Path Aggregation Network) 3) Head : YOLO-v3ResNet의 이해와 정리바로 앞 게시글에서 ResNet를 정리했는데 이는 백본을 정리하기 위해서였다.ResNet이 Image Classification task에서 깊은 모델로 성과를 보였지만 이러한 깊은 Network는 단지 image classification에서만 사용되는 것이 아니다. Detection, Segmentation, Pose Estimation, Depth Estimation 등에서 Backbone으로 사용된다.backbone은 입력이 처음 들어와서 출력에 관련된 모듈에 처리된 입력을 보내주는 역할이라고 생각할 수 있다. 여러가지 task가 몸의 각 부분이라고 생각하면 ResNet과 같은 classification model은 입력을 받아서 각 task에 맞는 모듈로 전달해주는 역할이다. 결국 객체를 검출하든 영역들을 나누든 Neural Network는 입력 이미지로부터 다양한 feature를 추출해야한다. 그 역할을 backbone 네트워크가 하는 것이다.요약: 다시 정리해서 왜 백본이 필요한가?Backbone은 큰 데이터셋(ImageNet등)에 사전 학습된(pretrained) 딥러닝 모델Backbone은 feature extractor(특징 추출기)을 수행하며 Backbone에 이미지를 넣으면 feature가 추출됨실 서비스에 딥러닝 모델을 적용하려면 (예: detection 서비스를 딥러닝 모델로 서빙 한다면) - Pretrained backbone을 기반 (즉 큰 데이터를 가지고 미리 backbone을 학습)으로 finetuning을 활용해서 target task의 데이터셋에서 학습하는 것이 성능을 확보하는 가장 좋은 방법  Computer_Vision, Study  review vision This post is licensed under  CC BY 4.0  by the author. Share              Comments powered by Disqus.  ')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://jeong-daniel.github.io/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%98-Backbone(%EB%B0%B1%EB%B3%B8)-%EC%A0%95%EB%A6%AC/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"post pl-1 pr-1 pl-md-2 pr-md-2\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4d5bce",
      "metadata": {
        "id": "5b4d5bce"
      },
      "source": [
        "`RecursiveCharacterTextSplitter`는 문서를 지정된 크기의 청크로 나눔\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8e9bf670",
      "metadata": {
        "id": "8e9bf670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a38783",
      "metadata": {
        "id": "49a38783"
      },
      "source": [
        "`FAISS` 혹은 `Chroma`와 같은 vectorstore는 이러한 청크를 바탕으로 문서의 벡터 표현을 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "62a8ca04",
      "metadata": {
        "id": "62a8ca04"
      },
      "outputs": [],
      "source": [
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a89f55",
      "metadata": {
        "id": "00a89f55"
      },
      "source": [
        "`vectorstore.as_retriever()`를 통해 생성된 검색기는 프롬프트와 `ChatOpenAI` 모델을 사용하여 새로운 내용을 생성\n",
        "\n",
        "`StrOutputParser`는 생성된 결과를 문자열로 파싱\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a59f677c",
      "metadata": {
        "id": "a59f677c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. \n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요. 줄바꿈을 해주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6d16128d",
      "metadata": {
        "id": "6d16128d"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "# 체인을 생성합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9370eb",
      "metadata": {
        "id": "be9370eb"
      },
      "source": [
        "스트리밍 출력을 위하여 `stream_response` 를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "78fed977",
      "metadata": {
        "id": "78fed977"
      },
      "outputs": [],
      "source": [
        "from langchain_teddynote.messages import stream_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4948a029",
      "metadata": {
        "id": "4948a029"
      },
      "source": [
        "\n",
        "\n",
        "> [LangSmith Trace](https://smith.langchain.com/o/e738ca73-da9f-5fcd-86bb-d729db658172)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "78275b37",
      "metadata": {
        "id": "78275b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "이미지 분석 기법 중 하나인 딥러닝 모델의 Backbone(백본)은 입력 이미지를 feature map으로 변형시켜주는 역할을 합니다. 대표적인 Backbone으로는 ImageNet 데이터셋으로 사전 학습된 VGG16, ResNet-50 등이 있습니다. \n",
            "\n",
            "Backbone은 입력 이미지로부터 다양한 특징을 추출하는 feature extractor 역할을 하며, 이 추출된 feature는 이후 Neck(넥)과 Head(헤드)로 전달되어 객체 검출, 분류 등의 작업을 수행합니다. \n",
            "\n",
            "객체 검출에서는 Backbone이 추출한 feature map을 기반으로 Location과 Classification 작업이 이루어지며, 이러한 과정은 One-Stage와 Two-Stage로 나뉘어 진행됩니다. \n",
            "\n",
            "결론적으로, Backbone은 이미지 분석에서 중요한 역할을 하며, 사전 학습된 모델을 활용하여 성능을 향상시키는 데 기여합니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"이미지 분석 기법\")\n",
        "# # 제너레이터에서 데이터를 하나씩 모아서 문자열로 합치기\n",
        "# answer_content = ''.join([chunk for chunk in answer])\n",
        "\n",
        "# # 결과 출력\n",
        "# print(answer_content)\n",
        "stream_response(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "93c96f34",
      "metadata": {
        "id": "93c96f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow를 사용하여 Backbone으로 배경과 각종 물체를 분리하는 Neck과 접힌 박막만 예측하는 Head를 구현하는 코드는 다음과 같이 작성할 수 있습니다. 아래 코드는 간단한 구조를 보여주며, 실제로는 데이터셋과 모델의 세부 사항에 따라 조정이 필요할 수 있습니다.\n",
            "\n",
            "```python\n",
            "import tensorflow as tf\n",
            "from tensorflow.keras import layers, models\n",
            "\n",
            "# Backbone: 예를 들어 ResNet50을 사용\n",
            "def create_backbone(input_shape):\n",
            "    backbone = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')\n",
            "    return backbone\n",
            "\n",
            "# Neck: Feature Pyramid Network (FPN) 예시\n",
            "def create_neck(backbone_output):\n",
            "    # FPN을 구현하는 간단한 예시\n",
            "    x = layers.Conv2D(256, (1, 1), padding='same')(backbone_output)\n",
            "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
            "    return x\n",
            "\n",
            "# Head: 접힌 박막 예측을 위한 간단한 구조\n",
            "def create_head(neck_output):\n",
            "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(neck_output)\n",
            "    x = layers.Conv2D(1, (1, 1), padding='same', activation='sigmoid')(x)  # 이진 분류를 위한 출력\n",
            "    return x\n",
            "\n",
            "# 전체 모델 생성\n",
            "def create_model(input_shape):\n",
            "    inputs = layers.Input(shape=input_shape)\n",
            "    backbone = create_backbone(input_shape)(inputs)\n",
            "    neck = create_neck(backbone)\n",
            "    outputs = create_head(neck)\n",
            "    \n",
            "    model = models.Model(inputs, outputs)\n",
            "    return model\n",
            "\n",
            "# 모델 사용 예시\n",
            "input_shape = (256, 256, 3)  # 입력 이미지 크기\n",
            "model = create_model(input_shape)\n",
            "model.summary()\n",
            "```\n",
            "\n",
            "위 코드는 ResNet50을 Backbone으로 사용하고, 간단한 FPN을 Neck으로, 그리고 접힌 박막을 예측하는 Head를 구성한 예시입니다. 실제 데이터셋에 맞게 학습 및 조정이 필요합니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"backbone으로 배경과 각종 물체를 분리하는 neck과 접힌 박막만 예측하는 head를 가진 tensorflow로 이루어진 코드를 부탁해. \")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "6fd1f686",
      "metadata": {
        "id": "6fd1f686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주어진 코드에서 fit 하는 방법은 다음과 같습니다.\n",
            "\n",
            "딥러닝 모델을 학습시키기 위해서는 일반적으로 `fit` 메서드를 사용합니다. 이 메서드는 모델에 데이터를 입력하고, 해당 데이터에 대해 학습을 수행합니다. \n",
            "\n",
            "1. **데이터 준비**: 먼저, 학습에 사용할 데이터셋을 준비해야 합니다. 이 데이터셋은 입력 데이터와 해당하는 레이블로 구성되어야 합니다.\n",
            "\n",
            "2. **모델 정의**: 사용할 딥러닝 모델을 정의합니다. 이 모델은 Backbone을 포함하여 Neck과 Head로 구성될 수 있습니다.\n",
            "\n",
            "3. **컴파일**: 모델을 컴파일하여 손실 함수와 최적화 알고리즘을 설정합니다.\n",
            "\n",
            "4. **fit 호출**: 준비된 데이터셋을 사용하여 `fit` 메서드를 호출합니다. 이때, 에포크 수와 배치 크기 등의 하이퍼파라미터를 설정할 수 있습니다.\n",
            "\n",
            "예를 들어, Keras를 사용하는 경우 다음과 같은 코드가 될 수 있습니다:\n",
            "\n",
            "```python\n",
            "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
            "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
            "```\n",
            "\n",
            "이렇게 하면 모델이 주어진 데이터에 대해 학습을 시작하게 됩니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"너가 준 코드에서 fit 하는 방법\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f507cd6b",
      "metadata": {
        "id": "f507cd6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backbone, Neck, Head 각각에 대해 다른 라벨링 파일을 사용할 필요는 없습니다. \n",
            "\n",
            "이들은 딥러닝 모델의 구조에서 서로 연결된 부분으로, Backbone은 입력 이미지를 feature map으로 변형하고, Neck은 이 feature map을 정제 및 재구성하며, Head는 최종적으로 예측 작업을 수행합니다. 따라서 하나의 라벨링 파일로도 이 모든 부분을 처리할 수 있습니다. \n",
            "\n",
            "하지만 특정한 요구사항이나 데이터셋에 따라 다르게 설정할 수도 있으니, 필요에 따라 조정할 수 있습니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"backbone과 neck, head 각각 다른 라벨링 파일을 줄 필욘 없어?\")\n",
        "stream_response(answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
