{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import v2 as T\n",
    "import os\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F   \n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "class Load_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, 'masks'))))\n",
    "        self.imgs = []\n",
    "        for self.img in self.masks:\n",
    "            self.img=''.join(self.img.split(\"_mask\"))\n",
    "            self.imgs.append(self.img)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, 'images', self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, 'masks', self.masks[idx])\n",
    "        img = read_image(img_path)\n",
    "        mask = read_image(mask_path)\n",
    "        obj_ids = torch.unique(mask)\n",
    "        print(obj_ids)\n",
    "        obj_ids = obj_ids[1:]\n",
    "        num_objs = len(obj_ids)\n",
    "\n",
    "        masks = (mask == obj_ids[:,None,None]).to(dtype = torch.uint8)\n",
    "        boxes = masks_to_boxes(masks)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        image_id = idx\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        img = tv_tensors.Image(img)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
    "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "dataset = Load_Dataset('./', get_transform(train=True))\n",
    "dataset_test = Load_Dataset('./', get_transform(train=False))\n",
    "\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:4])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[4:])\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:4])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[4:])\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
