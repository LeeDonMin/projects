{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 2. 데이터셋 로딩 함수 정의\n",
    "DATASET_PATH = 'Google_Recaptcha_V2_Images_Dataset/images/'\n",
    "ANNOTATION_FILE = 'annotations.json'\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    class_names = sorted(os.listdir(dataset_path))\n",
    "    image_paths = []\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            if os.path.isfile(img_path) and img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                image_paths.append(img_path)\n",
    "    \n",
    "    return class_names, image_paths\n",
    "\n",
    "# 3. 라벨링 함수 정의\n",
    "def label_images(image_paths, class_names):\n",
    "    annotations = {}\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Labeling Images\"):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"이미지를 불러올 수 없습니다: {img_path}\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        clones = img_rgb.copy()\n",
    "        bboxes = []\n",
    "        classes = []\n",
    "        \n",
    "        while True:\n",
    "            roi = cv2.selectROI(\"Image\", clones, fromCenter=False, showCrosshair=True)\n",
    "            if roi == (0,0,0,0):\n",
    "                break\n",
    "            x, y, w, h = roi\n",
    "            cv2.rectangle(clones, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.imshow(\"Image\", clones)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    class_idx = int(input(f\"클래스 선택 (0-{len(class_names)-1}) for selected region: \"))\n",
    "                    if 0 <= class_idx < len(class_names):\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"유효하지 않은 클래스 번호입니다.\")\n",
    "                except ValueError:\n",
    "                    print(\"숫자를 입력해주세요.\")\n",
    "            \n",
    "            bboxes.append([x, y, w, h])\n",
    "            classes.append(class_names[class_idx])\n",
    "        \n",
    "        annotations[img_path] = {\n",
    "            \"bboxes\": bboxes,\n",
    "            \"classes\": classes\n",
    "        }\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    with open(ANNOTATION_FILE, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "    print(f\"라벨 정보가 {ANNOTATION_FILE}에 저장되었습니다.\")\n",
    "\n",
    "# 4. 데이터셋 로드 및 라벨링 실행\n",
    "class_names, image_paths = load_dataset(DATASET_PATH)\n",
    "print(f\"클래스 목록: {class_names}\")\n",
    "print(f\"총 이미지 수: {len(image_paths)}\")\n",
    "\n",
    "label_images(image_paths, class_names)  # 이 셀은 주석을 제거하고 실행해야 합니다.\n",
    "\n",
    "# 5. 라벨 데이터 로드\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "annotations = load_annotations(ANNOTATION_FILE)\n",
    "print(f\"라벨링된 이미지 수: {len(annotations)}\")\n",
    "\n",
    "# 6. 데이터 전처리 함수 정의\n",
    "def preprocess_data(image_paths, annotations, class_names, num_boxes=10, num_classes=12, input_shape=(224, 224)):\n",
    "    images = []\n",
    "    y_bboxes = []\n",
    "    y_classes = []\n",
    "    y_confidences = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"이미지를 불러올 수 없습니다: {img_path}\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resized = cv2.resize(img_rgb, input_shape)\n",
    "        img_normalized = img_resized / 255.0\n",
    "        images.append(img_normalized)\n",
    "        \n",
    "        ann = annotations.get(img_path, {})\n",
    "        bboxes = ann.get('bboxes', [])\n",
    "        classes = ann.get('classes', [])\n",
    "        \n",
    "        bboxes_padded = bboxes[:num_boxes]\n",
    "        classes_padded = classes[:num_boxes]\n",
    "        \n",
    "        bboxes_normalized = []\n",
    "        for bbox in bboxes_padded:\n",
    "            x_min, y_min, w, h = bbox\n",
    "            x_max = x_min + w\n",
    "            y_max = y_min + h\n",
    "            x_min_norm = x_min / input_shape[0]\n",
    "            y_min_norm = y_min / input_shape[1]\n",
    "            x_max_norm = x_max / input_shape[0]\n",
    "            y_max_norm = y_max / input_shape[1]\n",
    "            bboxes_normalized.extend([x_min_norm, y_min_norm, x_max_norm, y_max_norm])\n",
    "        \n",
    "        while len(bboxes_normalized) < num_boxes * 4:\n",
    "            bboxes_normalized.extend([0.0, 0.0, 0.0, 0.0])\n",
    "        \n",
    "        y_bboxes.append(bboxes_normalized)\n",
    "        \n",
    "        classes_one_hot = []\n",
    "        for cls in classes_padded:\n",
    "            one_hot = [0] * num_classes\n",
    "            one_hot[class_names.index(cls)] = 1\n",
    "            classes_one_hot.extend(one_hot)\n",
    "        \n",
    "        while len(classes_one_hot) < num_boxes * num_classes:\n",
    "            classes_one_hot.extend([0] * num_classes)\n",
    "        \n",
    "        y_classes.append(classes_one_hot)\n",
    "        \n",
    "        confidences = [1.0] * len(bboxes_padded)\n",
    "        while len(confidences) < num_boxes:\n",
    "            confidences.append(0.0)\n",
    "        y_confidences.append(confidences)\n",
    "    \n",
    "    X = np.array(images, dtype=np.float32)\n",
    "    y_bboxes = np.array(y_bboxes, dtype=np.float32)\n",
    "    y_classes = np.array(y_classes, dtype=np.float32)\n",
    "    y_confidences = np.array(y_confidences, dtype=np.float32)\n",
    "    \n",
    "    y_true = np.concatenate([y_bboxes, y_classes, y_confidences], axis=1)\n",
    "    \n",
    "    return X, y_true\n",
    "\n",
    "# 7. 데이터 전처리 실행\n",
    "train_image_paths = list(annotations.keys())\n",
    "train_annotations = annotations\n",
    "\n",
    "X_train, y_train = preprocess_data(\n",
    "    train_image_paths,\n",
    "    train_annotations,\n",
    "    class_names,\n",
    "    num_boxes=num_boxes,\n",
    "    num_classes=num_classes,\n",
    "    input_shape=(224, 224)\n",
    ")\n",
    "\n",
    "print(f\"훈련 데이터 크기: {X_train.shape}\")\n",
    "print(f\"훈련 라벨 크기: {y_train.shape}\")\n",
    "\n",
    "# 8. Residual Block 및 Attention Layer 정의\n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, filters, stride=1, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=stride, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.downsample = None\n",
    "        if stride != 1:\n",
    "            self.downsample = models.Sequential([\n",
    "                layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same', use_bias=False),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        identity = inputs\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.downsample(inputs, training=training)\n",
    "        \n",
    "        out = layers.add([out, identity])\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class AttentionLayerWrapper(layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(AttentionLayerWrapper, self).__init__(**kwargs)\n",
    "        self.query = layers.Conv2D(filters, kernel_size=1)\n",
    "        self.key = layers.Conv2D(filters, kernel_size=1)\n",
    "        self.value = layers.Conv2D(filters, kernel_size=1)\n",
    "        self.softmax = layers.Softmax(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        height = tf.shape(inputs)[1]\n",
    "        width = tf.shape(inputs)[2]\n",
    "        \n",
    "        query = self.query(inputs)  # (batch, height, width, filters)\n",
    "        key = self.key(inputs)      # (batch, height, width, filters)\n",
    "        value = self.value(inputs)  # (batch, height, width, filters)\n",
    "        \n",
    "        # Reshape for matrix multiplication\n",
    "        query = tf.reshape(query, [batch_size, height * width, -1])  # (batch, height*width, filters)\n",
    "        key = tf.reshape(key, [batch_size, height * width, -1])      # (batch, height*width, filters)\n",
    "        value = tf.reshape(value, [batch_size, height * width, -1])  # (batch, height*width, filters)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = tf.matmul(query, key, transpose_b=True)    # (batch, height*width, height*width)\n",
    "        attention_weights = self.softmax(attention_scores)           # (batch, height*width, height*width)\n",
    "        \n",
    "        # Compute attention output\n",
    "        out = tf.matmul(attention_weights, value)                   # (batch, height*width, filters)\n",
    "        out = tf.reshape(out, [batch_size, height, width, -1])     # (batch, height, width, filters)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 모델 구축 함수 정의\n",
    "def build_object_detection_model(num_classes, num_boxes=10, input_shape=(224, 224, 3)):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Backbone: 간단한 CNN 블록 (Residual Connections 포함)\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(input_layer)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)  # (112, 112, 64)\n",
    "    \n",
    "    # Residual Block\n",
    "    x = ResidualBlock(128, stride=1)(x)  # (112, 112, 128)\n",
    "    \n",
    "    # Attention Layer\n",
    "    x = AttentionLayerWrapper(128)(x)  # (112, 112, 128)\n",
    "    \n",
    "    # Additional Conv2D\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Feature Maps 추출\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)  # (56, 56, 256)\n",
    "    \n",
    "    # Flatten 및 Dense Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Detection Heads\n",
    "    bbox_output = layers.Dense(num_boxes * 4, activation='sigmoid', name='bbox')(x)\n",
    "    class_output = layers.Dense(num_boxes * num_classes, activation='softmax', name='class')(x)\n",
    "    confidence_output = layers.Dense(num_boxes, activation='sigmoid', name='confidence')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=[bbox_output, class_output, confidence_output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 커스텀 손실 함수 정의\n",
    "def custom_object_detection_loss(y_true, y_pred, num_boxes, num_classes):\n",
    "    true_bbox = y_true[:, :num_boxes * 4]\n",
    "    true_class = y_true[:, num_boxes * 4:num_boxes * 4 + num_boxes * num_classes]\n",
    "    true_confidence = y_true[:, num_boxes * 4 + num_boxes * num_classes:]\n",
    "    \n",
    "    pred_bbox = y_pred[0]\n",
    "    pred_class = y_pred[1]\n",
    "    pred_confidence = y_pred[2]\n",
    "    \n",
    "    bbox_loss = tf.reduce_mean(tf.square(true_bbox - pred_bbox))\n",
    "    \n",
    "    class_loss = tf.reduce_mean(\n",
    "        tf.keras.losses.categorical_crossentropy(true_class, pred_class)\n",
    "    )\n",
    "    \n",
    "    confidence_loss = tf.reduce_mean(\n",
    "        tf.keras.losses.binary_crossentropy(true_confidence, pred_confidence)\n",
    "    )\n",
    "    \n",
    "    total_loss = bbox_loss + class_loss + confidence_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 모델 생성 및 컴파일\n",
    "model = build_object_detection_model(num_classes=num_classes, num_boxes=num_boxes, input_shape=(224, 224, 3))\n",
    "model.summary()\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    return custom_object_detection_loss(y_true, y_pred, num_boxes, num_classes)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 모델 훈련\n",
    "model.fit(\n",
    "    X_train, \n",
    "    [\n",
    "        y_train[:, :num_boxes * 4], \n",
    "        y_train[:, num_boxes * 4:num_boxes * 4 + num_boxes * num_classes], \n",
    "        y_train[:, num_boxes * 4 + num_boxes * num_classes:]\n",
    "    ],\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMS 적용된 예측 및 시각화 실행\n",
    "sample_image_path = train_image_paths[0]  # 샘플 이미지 경로\n",
    "predict_and_visualize_with_nms(\n",
    "    model, \n",
    "    sample_image_path, \n",
    "    class_names, \n",
    "    num_boxes=num_boxes, \n",
    "    num_classes=num_classes, \n",
    "    input_shape=(224, 224), \n",
    "    max_output_size=10, \n",
    "    iou_threshold=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save('object_detection_model.keras')\n",
    "print(\"모델이 'object_detection_model.h5'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = tf.keras.models.load_model('object_detection_model.keras', custom_objects={\n",
    "    'ResidualBlock': ResidualBlock,\n",
    "    'AttentionLayerWrapper': AttentionLayerWrapper\n",
    "})\n",
    "print(\"모델이 성공적으로 로드되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class BoundingBoxEnv:\n",
    "    def __init__(self, image_paths, input_shape=(64, 64)):\n",
    "        self.image_paths = image_paths\n",
    "        self.input_shape = input_shape\n",
    "        self.current_image_idx = 0\n",
    "        self.current_image = None\n",
    "        self.done = False\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"환경을 초기화하고 새 이미지를 로드합니다.\"\"\"\n",
    "        if self.current_image_idx >= len(self.image_paths):\n",
    "            self.done = True\n",
    "            return None\n",
    "        \n",
    "        # 새로운 이미지를 불러옵니다.\n",
    "        img_path = self.image_paths[self.current_image_idx]\n",
    "        self.current_image = cv2.imread(img_path)\n",
    "        \n",
    "        self.current_image_idx += 1\n",
    "        return self.current_image\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        에이전트가 바운딩 박스를 설정하면 보상을 계산하여 반환합니다.\n",
    "        action은 [x_min, y_min, x_max, y_max]로 표현됩니다.\n",
    "        \"\"\"\n",
    "        predicted_bbox = action\n",
    "        true_bbox = [20, 20, 40, 40]  # 간단하게 실제 바운딩 박스를 임의로 설정\n",
    "        iou = self._iou(predicted_bbox, true_bbox)\n",
    "        reward = iou  # IoU를 보상으로 사용\n",
    "        done = True  # 한 번 예측하면 종료\n",
    "        return self.current_image, reward, done\n",
    "\n",
    "    def _iou(self, bbox1, bbox2):\n",
    "        \"\"\"두 바운딩 박스 사이의 IoU를 계산합니다.\"\"\"\n",
    "        x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "        x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "\n",
    "        inter_x_min = max(x1_min, x2_min)\n",
    "        inter_y_min = max(y1_min, y2_min)\n",
    "        inter_x_max = min(x1_max, x2_max)\n",
    "        inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "        inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "        bbox1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "        bbox2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "        union_area = bbox1_area + bbox2_area - inter_area\n",
    "        return inter_area / union_area if union_area != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DDQNAgent:\n",
    "    def __init__(self, input_shape, num_actions, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_min=0.1, epsilon_decay=0.995):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions  # 바운딩 박스 설정을 위한 행동 수 (x_min, y_min, x_max, y_max)\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon  # 탐색과 활용 사이의 균형\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.batch_size = 32\n",
    "        self.update_target_network_steps = 1000\n",
    "        self.steps = 0\n",
    "        \n",
    "        self.q_network = self.build_network()\n",
    "        self.target_network = self.build_network()\n",
    "        self.update_target_network()\n",
    "\n",
    "    def build_network(self):\n",
    "        \"\"\"간단한 Conv2D 기반의 Q-Network 생성\"\"\"\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dense(self.num_actions, activation='linear'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def update_target_network(self):\n",
    "        \"\"\"Q-Network의 가중치를 Target Network로 복사\"\"\"\n",
    "        self.target_network.set_weights(self.q_network.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"경험을 메모리에 저장\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"epsilon-greedy 정책으로 행동 선택\"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(0, self.num_actions)\n",
    "        q_values = self.q_network.predict(np.expand_dims(state, axis=0))\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"Q-Network 학습\"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np.array([transition[0] for transition in minibatch])\n",
    "        actions = np.array([transition[1] for transition in minibatch])\n",
    "        rewards = np.array([transition[2] for transition in minibatch])\n",
    "        next_states = np.array([transition[3] for transition in minibatch])\n",
    "        dones = np.array([transition[4] for transition in minibatch])\n",
    "\n",
    "        q_values = self.q_network.predict(states)\n",
    "        target_q_values = self.target_network.predict(next_states)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                q_values[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                q_values[i][actions[i]] = rewards[i] + self.gamma * np.amax(target_q_values[i])\n",
    "\n",
    "        self.q_network.train_on_batch(states, q_values)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        if self.steps % self.update_target_network_steps == 0:\n",
    "            self.update_target_network()\n",
    "\n",
    "    def train(self, env, episodes=1000):\n",
    "        \"\"\"환경에서 에이전트를 학습\"\"\"\n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "            self.steps = 0\n",
    "\n",
    "            while not done:\n",
    "                self.steps += 1\n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward, done = env.step(action)\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                self.replay()\n",
    "\n",
    "            print(f\"Episode: {episode+1}/{episodes}, Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 이미지 경로\n",
    "image_paths = ['Google_Recaptcha_V2_Images_Dataset/images/Bicycle/Bicycle (1).png','Google_Recaptcha_V2_Images_Dataset/images/Bicycle/Bicycle (3).png']  # 실제 이미지 경로로 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m DDQNAgent(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m3\u001b[39m), num_actions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# x_min, y_min, x_max, y_max\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 에이전트 학습 실행\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m agent\u001b[38;5;241m.\u001b[39mtrain(env, episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 93\u001b[0m, in \u001b[0;36mDDQNAgent.train\u001b[1;34m(self, env, episodes)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     92\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoose_action(state)\n\u001b[1;32m---> 93\u001b[0m next_state, reward, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember(state, action, reward, next_state, done)\n\u001b[0;32m     95\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m, in \u001b[0;36mBoundingBoxEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     32\u001b[0m predicted_bbox \u001b[38;5;241m=\u001b[39m action\n\u001b[0;32m     33\u001b[0m true_bbox \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m40\u001b[39m]  \u001b[38;5;66;03m# 간단하게 실제 바운딩 박스를 임의로 설정\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iou(predicted_bbox, true_bbox)\n\u001b[0;32m     35\u001b[0m reward \u001b[38;5;241m=\u001b[39m iou  \u001b[38;5;66;03m# IoU를 보상으로 사용\u001b[39;00m\n\u001b[0;32m     36\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# 한 번 예측하면 종료\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m, in \u001b[0;36mBoundingBoxEnv._iou\u001b[1;34m(self, bbox1, bbox2)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iou\u001b[39m(\u001b[38;5;28mself\u001b[39m, bbox1, bbox2):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"두 바운딩 박스 사이의 IoU를 계산합니다.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     x1_min, y1_min, x1_max, y1_max \u001b[38;5;241m=\u001b[39m bbox1\n\u001b[0;32m     42\u001b[0m     x2_min, y2_min, x2_max, y2_max \u001b[38;5;241m=\u001b[39m bbox2\n\u001b[0;32m     44\u001b[0m     inter_x_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(x1_min, x2_min)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "env = BoundingBoxEnv(image_paths=image_paths, input_shape=(120, 120, 3))\n",
    "agent = DDQNAgent(input_shape=(120, 120, 3), num_actions=4)  # x_min, y_min, x_max, y_max\n",
    "\n",
    "# 에이전트 학습 실행\n",
    "agent.train(env, episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
