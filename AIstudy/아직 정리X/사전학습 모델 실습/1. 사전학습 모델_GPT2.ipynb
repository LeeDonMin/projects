{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\humming\\anaconda3\\lib\\site-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tf_keras\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tf_keras) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.32.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (74.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (1.66.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\humming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (13.3.5)\n",
            "Requirement already satisfied: namex in c:\\users\\humming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\humming\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\humming\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf_keras) (0.1.0)\n",
            "Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/1.7 MB 487.6 kB/s eta 0:00:04\n",
            "   ------ --------------------------------- 0.3/1.7 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 0.8/1.7 MB 5.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.3/1.7 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.7/1.7 MB 7.3 MB/s eta 0:00:00\n",
            "Installing collected packages: tf_keras\n",
            "Successfully installed tf_keras-2.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue2kOQhXTAMU",
        "outputId": "2f62c68c-3061-472b-e4d1-aa3bd30f8aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\humming\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "107b8df9ba1c4ccfa7f925551605ff40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\humming\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\humming\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c61f52329e674c8ab356875a86212fa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab3e5e5d30d464ca16a97a646719077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "691cf88dd32e4c9da615e6692c6f1915",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e865ab5f9a403fbcab88634f2af0e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\humming\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15a34c1a4f4048ef9a353d64c009ce29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\humming\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# gpt2 모델 불러오기\n",
        "MODEL_NAME = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = TFGPT2LMHeadModel.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OWLd_J6lXz_t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated sentence 1: I am currently learning machine learning. I have been working on this for a while now and it is very exciting to be able to do so.\n",
            "\n",
            "What are some of the challenges that you face in your job as a software developer? How do you deal with these challenges? What can you tell us about how you handle them?\n",
            "\n",
            "\n",
            "The most challenging part of my job is figuring out how to get things done. There are a lot of different types of tasks that need to happen, but\n",
            "Generated sentence 2: I am currently learning machine learning. I have been working on this for a while now and it is very exciting to be able to do so.\n",
            "\n",
            "What are some of the challenges that you face in your job as a software developer? How do you deal with these challenges? What can you tell us about how you handle them?\n",
            "\n",
            "\n",
            "The most challenging part of my job is figuring out how to get things done. There are a lot of different types of tasks that I need to perform,\n",
            "Generated sentence 3: I am currently learning machine learning. I have been working on this for a while now and it is very exciting to be able to do so.\n",
            "\n",
            "What are some of the challenges that you face in your job as a software developer? How do you deal with these challenges? What can you tell us about how you handle them?\n",
            "\n",
            "\n",
            "The most challenging part of my job is figuring out how to get things done. There are a lot of different types of tasks that I need to accomplish,\n",
            "Generated sentence 4: I am currently learning machine learning. I have been working on this for a while now and it is very exciting to be able to do so.\n",
            "\n",
            "What are some of the challenges that you face in your job as a software developer? How do you deal with these challenges? What can you tell us about how you handle them?\n",
            "\n",
            "\n",
            "The most challenging part of my job is figuring out how to get things done. There are a lot of different types of tasks that need to happen, and\n",
            "Generated sentence 5: I am currently learning machine learning. I have been working on this for a while now and it is very exciting to be able to do so.\n",
            "\n",
            "What are some of the challenges that you face in your job as a software developer? How do you deal with these challenges? What can you tell us about how you handle them?\n",
            "\n",
            "\n",
            "The most challenging part of my job is figuring out how to get things done. There are a lot of different types of tasks that I need to complete,\n"
          ]
        }
      ],
      "source": [
        "# 문장 생성하기 전, 초기 문장 입력(영어)\n",
        "text = 'I am currently learning machine learning'\n",
        "\n",
        "# encode를 통해 input text 인코딩\n",
        "input_ids = tokenizer.encode(text, return_tensors='tf')\n",
        "\n",
        "# attention mask 생성: 패딩 토큰이 있는지 확인하고, attention mask를 설정\n",
        "attention_mask = tf.ones(input_ids.shape)\n",
        "\n",
        "# 인코딩된 input text 기반, 문장 생성(max_length 지정)\n",
        "output = model.generate(input_ids,\n",
        "                        attention_mask=attention_mask,  # attention mask 추가\n",
        "                        max_length=100,  # 5000은 너무 길기 때문에 100 정도로 수정\n",
        "                        repetition_penalty=2.0,\n",
        "                        num_beams=5,\n",
        "                        num_return_sequences=5,\n",
        "                        no_repeat_ngram_size=2,\n",
        "                        early_stopping=True,\n",
        "                        pad_token_id=tokenizer.eos_token_id)  # pad_token_id를 eos_token_id로 설정\n",
        "\n",
        "# 생성된 토큰을 텍스트로 디코딩\n",
        "generated_sentences = [tokenizer.decode(sentence, skip_special_tokens=True) for sentence in output.numpy().tolist()]\n",
        "\n",
        "# 생성된 문장 출력\n",
        "for i, sentence in enumerate(generated_sentences):\n",
        "    print(f\"Generated sentence {i+1}: {sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I am currently learning machine learning and I have been working on it for a while.\\nThe first thing that comes to mind is the fact that you can't just write code in Python, because there are so many different languages out here (Python 2 or 3). You need an interpreter which will run your program as fast as possible without any overhead of course! So if we want to do something like this:\\n\\n<|endoftext|>\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(output_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[40, 716, 3058, 4673, 4572, 4673]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJOBVKULO8Op",
        "outputId": "17b0652f-6aa1-4794-d8ec-a3f1238bdc01"
      },
      "outputs": [],
      "source": [
        "# 생성된 문장 decode하여 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy3iVJgfnkMi"
      },
      "outputs": [],
      "source": [
        "# 내부 속성을 이용해 문장 깔끔하게 출력\n",
        "beam_output = model.generate(\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ2N28_ZPZsd",
        "outputId": "2ec781bc-97c3-4763-ca0a-b6e9c0f8d393"
      },
      "outputs": [],
      "source": [
        "# 생성된 문장 decode하여 출력 (skip_special_tokens=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
